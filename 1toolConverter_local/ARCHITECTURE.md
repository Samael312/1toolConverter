# main.py

# Architecture: AplicaciÃ³n Conversor Universal (Keyter / iPro / Cefa / Dixell)

## 1. Overview

Este archivo constituye el **punto de entrada** de la aplicaciÃ³n Conversor Universal, encargada de:

* Inicializar la interfaz NiceGUI
* Gestionar el flujo de subida de archivos
* Seleccionar dinÃ¡micamente quÃ© backend procesarÃ¡ los archivos
* Unificar criterios de procesamiento para **Keyter**, **iPro**, **Cefa** y **Dixell**
* Coordinar la comunicaciÃ³n entre UI y lÃ³gica de negocio

Este mÃ³dulo NO procesa datos directamente; delega toda la lÃ³gica pesada a los backends correspondientes.

---

## 2. Arquitectura General

```
+------------------------+
|     NiceGUI UI         |
|  (presentation/ui.py)  |
+-----------+------------+
            |
            | process_html_callback
            v
+-----------+------------+
|   unified_process_file |
|  SelecciÃ³n de backend  |
+-----------+------------+
            |
   +--------+--------+-------------+-----------------+
   |                 |             |                 |
   v                 v             v                 v
Keyter Backend   iPro Backend   Cefa Backend   Dixell Backend
(process_html,   (convert_excel) (process_pdf) (process_multiple_pdfs)
 process_excel)       Excel          PDF              PDFs
```

---

## 3. Componentes Principales

### 3.1 `unified_process_file(mode, filename, file_bytes)`

FunciÃ³n centralizadora que decide quÃ© backend usar.

**Responsabilidades:**

* Determinar quÃ© tipo de entrada corresponde segÃºn `mode`
* Manejar diferencias entre:

  * Backends de un solo archivo (Keyter, iPro, Cefa)
  * Backend multi-archivo (Dixell)
* Llamar al backend apropiado
* Manejar errores y notificar a la UI

**Backends soportados:**

* **Keyter** â†’ permite HTML o Excel
* **iPro** â†’ solo Excel
* **Cefa** â†’ solo PDF
* **Dixell** â†’ varios PDF simultÃ¡neos

---

## 4. Flujo de Procesamiento por Backend

### 4.1 Keyter

```
Si ext âˆˆ {html, htm} â†’ backend.Keyter.Keyter.process_html
Si ext âˆˆ {xls, xlsx, xlsm} â†’ backend.Keyter.KeyterNew.process_excel
```

Produce un DataFrame ya alineado al esquema `LIBRARY_COLUMNS`.

### 4.2 iPro

```
backend.iPro.ipro.convert_excel_to_dataframe
```

Convierte Excel iPro en tabla normalizada.

### 4.3 Cefa

```
backend.Cefa.cefa.process_pdf
```

Parser especializado en PDFs con tablas estructuradas con niveles/categorÃ­as.

### 4.4 Dixell

```
backend.Dixell.dixell2.process_multiple_pdfs(lista_de_bytes)
```

Backend mÃ¡s complejo: procesa mÃºltiples PDFs, unifica cabeceras y reglas.

---

## 5. Interfaz (NiceGUI)

La interfaz se crea mediante:

```
HTMLConverterUI(process_html_callback=process_with_backend)
```

`process_with_backend` actÃºa como adaptador entre la UI y el proceso unificado.

**HTMLConverterUI proporciona:**

* Selector de backend
* Cargador de uno o varios archivos segÃºn el backend
* Vista previa y exportaciÃ³n de resultados
* Mensajes de error mediante `ui.notify`

---

## 6. Modo de EjecuciÃ³n

El mÃ³dulo se comporta como aplicaciÃ³n interactiva NiceGUI.

```
main()          â†’ Construye la UI
ui.run()        â†’ Lanza servidor web local
```

La app soporta recarga automÃ¡tica (`reload=True`).

---

## 7. Control de Errores

* Uso intensivo de `logger.exception` para capturar trazas completas
* Notificaciones en UI si ocurre una excepciÃ³n en backends
* PrevenciÃ³n de ejecuciÃ³n sin selecciÃ³n de backend

---

## 8. DiseÃ±o y FilosofÃ­a del MÃ³dulo

* **No lÃ³gica de transformaciÃ³n**: todo se delega
* **Router de backends**: mapear tipo de archivo a funciÃ³n procesadora
* **DiseÃ±o extensible**: se puede agregar un backend nuevo aÃ±adiendo un nuevo modo en `unified_process_file`
* **UI independiente**: el backend nunca conoce la UI; la UI solo conoce un callback

---

## 9. Posibles Mejoras Futuras

* AÃ±adir cola asÃ­ncrona para procesar PDFs grandes
* AÃ±adir validaciones en la UI (extensiones permitidas por backend)
* Mostrar preview de DataFrames antes de exportar
* Cachear resultados para evitar reprocesar el mismo archivo durante la sesiÃ³n

---

## 10. Resumen

Este archivo actÃºa como **punto de orquestaciÃ³n** entre UI y mÃºltiples backends, manteniendo el procesamiento modular, escalable y fÃ¡cilmente extensible sin comprometer la interfaz visual.

-------------------------------------------------------------------------------------------------------------------------------

# Arquitectura de la Interfaz (HTMLConverterUI)

Este documento describe la arquitectura funcional y estructural de la interfaz construida con **NiceGUI**, cuyo objetivo es convertir y clasificar parÃ¡metros provenientes de archivos HTML, Excel o PDF, dependiendo del backend seleccionado.

---

## ğŸ“Œ 1. Estructura General

La interfaz estÃ¡ encapsulada en la clase `HTMLConverterUI`, que actÃºa como **controlador de UI** siguiendo una arquitectura modular basada en:

* **GestiÃ³n de estado interno**
* **Eventos de interacciÃ³n del usuario**
* **RepresentaciÃ³n visual mediante componentes NiceGUI**
* **Procesamiento delegado a un callback externo (`process_html_callback`)**

---

## ğŸ“Œ 2. Componentes Principales

### 2.1 InicializaciÃ³n del estado

* Archivos cargados (`uploaded_file_contents`, `uploaded_file_names`)
* Datos procesados (`processed_data`)
* Datos agrupados (`grouped_data`)
* Backend seleccionado
* Selecciones de filas en ambas tablas

El estado permite que la interfaz sea reactiva y consistente durante la sesiÃ³n del usuario.

---

### 2.2 Estructura visual

La interfaz se divide en tarjetas visibles secuencialmente:

1. **Selector de backend**
2. **Subida de archivo(s)**
3. **Procesamiento y tabla principal**
4. **Tabla de variables clasificadas**

Estas se muestran u ocultan dinÃ¡micamente segÃºn el avance del usuario.

---

## ğŸ“Œ 3. Flujo del Usuario

### Paso 1 â€” Seleccionar Backend

Define:

* Tipos de archivo permitidos
* Permisos automÃ¡ticos para categories segÃºn lÃ³gica del backend
* NÃºmero de archivos permitidos (e.g. mÃºltiples PDFs para Dixell)

### Paso 2 â€” Subir archivo(s)

La interfaz:

* Lee bytes del archivo
* Valida segÃºn backend
* Activa/desactiva botones segÃºn sea necesario

### Paso 3 â€” Procesar archivo

Uso del callback externo:

* Para backends simples: procesa solo el Ãºltimo archivo
* Para Dixell: procesa lista de PDFs

### Paso 4 â€” Mostrar Tabla Principal

Incluye:

* Filtros por columna
* Filtro por grupos
* Campos editables directamente en la tabla
* Selectores tipo dropdown para `system_category` y `view`

### Paso 5 â€” Clasificar variables

Mediante:

* SelecciÃ³n mÃºltiple
* Selector de grupo
* BotÃ³n "Asignar grupo"

### Paso 6 â€” Tabla de Clasificadas

Permite:

* Filtrar
* Buscar
* Eliminar filas
* Vaciar tabla entera
* Exportar

---

## ğŸ“Œ 4. LÃ³gica de ClasificaciÃ³n

La clasificaciÃ³n modifica dinÃ¡micamente:

* system_category
* view
* permisos de lectura/escritura (`read`, `write`)
* sampling (mapa dependiente de categorÃ­a)

AdemÃ¡s la categorÃ­a **STATUS** fuerza `view='basic'`.

La categorÃ­a **ALARM** limpia view.

La vista **primary** solo puede existir en una fila a la vez.

---

## ğŸ“Œ 5. SincronizaciÃ³n entre Tablas

Cada cambio en la tabla principal:

* Sincroniza el DataFrame interno
* Actualiza tabla de grupos si la fila pertenece a un grupo vÃ¡lido

Cada cambio en la tabla de grupos:

* Sincroniza la tabla principal

Es una sincronizaciÃ³n **bidireccional**, manteniendo consistencia del sistema.

---

## ğŸ“Œ 6. EdiciÃ³n de Campos

Los campos editables se generan mediante slots dinÃ¡micos que incluyen:

* QInput (texto o nÃºmero)
* BotÃ³n de confirmaciÃ³n

Cada cambio dispara `handle_field_change()`.

Campos editables:

* register
* read
* write
* sampling
* minvalue
* maxvalue
* unit
* description
* name

---

## ğŸ“Œ 7. Exportaciones

La interfaz permite:

### âœ” Exportar parÃ¡metros procesados

* Archivo Excel con parÃ¡metros completos

### âœ” Exportar parÃ¡metros clasificados

* Archivo Excel con solo filas agrupadas

### âœ” Exportar mapa de variables personalizado

* Usuario selecciona columnas especÃ­ficas

Usa archivos temporales gestiÃ³n automÃ¡tica de limpieza.

---

## ğŸ“Œ 8. Manejo de eventos NiceGUI

La interfaz depende de mÃºltiples eventos:

* `on_upload`
* `on_change`
* `on_click`
* `on_pagination_change`
* Slots personalizados `estado-change`, `view-change`, `*-change`

Toda la UI se reconstruye o actualiza sin recargarse.

---

## ğŸ“Œ 9. Arquitectura por MÃ³dulos

```
HTMLConverterUI
â”‚
â”œâ”€â”€ Estado interno
â”‚   â”œâ”€â”€ archivos cargados
â”‚   â”œâ”€â”€ processed_data
â”‚   â”œâ”€â”€ grouped_data
â”‚   â””â”€â”€ seleccionados
â”‚
â”œâ”€â”€ Interfaz grÃ¡fica
â”‚   â”œâ”€â”€ selector de backend
â”‚   â”œâ”€â”€ mÃ³dulo de subida
â”‚   â”œâ”€â”€ mÃ³dulo de procesamiento
â”‚   â”œâ”€â”€ tabla principal
â”‚   â””â”€â”€ tabla clasificada
â”‚
â”œâ”€â”€ LÃ³gica de negocio
â”‚   â”œâ”€â”€ clasificaciÃ³n automÃ¡tica
â”‚   â”œâ”€â”€ asignaciÃ³n de permisos
â”‚   â”œâ”€â”€ sincronizaciÃ³n bidireccional
â”‚   â”œâ”€â”€ filtros y bÃºsquedas
â”‚   â””â”€â”€ paginaciÃ³n
â”‚
â””â”€â”€ ExportaciÃ³n
    â”œâ”€â”€ Excel completo
    â”œâ”€â”€ Excel de grupos
    â””â”€â”€ Mapa personalizado
```

---

## ğŸ“Œ 10. Extensibilidad

La arquitectura estÃ¡ pensada para:

* **Agregar nuevos backends** fÃ¡cilmente
* **Incorporar nuevas columnas**
* **Modificar lÃ³gica de clasificaciÃ³n** sin tocar la UI
* **Agregar nuevos formatos de exportaciÃ³n**

---
---------------------------------------------------------------------------------------
# Listado de Backends
---------------------------------------------------------------------------------------
## Backend Keyter y NewKeyter

# Arquitectura del Backend Keyter

Este documento describe la arquitectura interna de los dos mÃ³dulos backend:

* **NewKeter.py** â†’ Procesamiento complejo de archivos Excel multipestaÃ±a.
* **Keyter.py** â†’ Procesamiento de archivos HTML en tablas.

Ambos producen un DataFrame unificado con formato estÃ¡ndar Keyter.

---

# 1. Objetivo del Backend

El propÃ³sito del backend Keyter es transformar archivos de entrada (Excel o HTML) provenientes de diferentes sistemas de climatizaciÃ³n/automatizaciÃ³n en un Ãºnico DataFrame con estructura uniforme, que luego se exporta a un Excel "procesado".

El resultado final siempre contiene las columnas definidas en `LIBRARY_COLUMNS`.

---

# 2. Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Archivo origen      â”‚  (.xlsx / .html)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parser de entrada   â”‚  (Excel o HTML â†’ DataFrames crudos)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ mÃºltiples hojas/tablas
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Motor de procesamiento      â”‚  (_process_dataframe)
â”‚ - Limpieza                  â”‚
â”‚ - AsignaciÃ³n de columnas    â”‚
â”‚ - NormalizaciÃ³n categorÃ­as  â”‚
â”‚ - Permisos R/W              â”‚
â”‚ - length (1bit / 16bit...)  â”‚
â”‚ - sampling                  â”‚
â”‚ - l10n                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ DataFrames procesados
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UnificaciÃ³n            â”‚  (concat)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reindexado final (LIBRARY_COLUMNS)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ExportaciÃ³n a Excel    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 3. Arquitectura de **NewKeter.py** (Procesador Excel)

## 3.1 Flujo de ejecuciÃ³n principal

```
process_excel() â†’ procesa todas las hojas desde memoria
process_excel_file() â†’ procesa un archivo .xlsx desde disco
```

### Pasos:

1. **Cargar archivo Excel** con `openpyxl` permitiendo macros (VBA).
2. **Recorrer todas las hojas** o las tres principales (ANALOG, INTEGER, BOOL).
3. **Detectar bloques por color**: filas verdes marcan inicio de categorÃ­a.
4. **Construir DataFrame por hoja** con trazabilidad del nombre de hoja.
5. **Concatenar todos los DataFrames**.
6. **Procesar DataFrame general** mediante `_process_dataframe()`.
7. **Agregar columnas por defecto** y reindexar.
8. **Exportar a Excel.
   **

## 3.2 Estructura interna

### MÃ³dulos de procesamiento:

* `_apply_column_mapping1()` â†’ renombre inteligente sensible a mayÃºsculas.
* `_process_specific_columns()` â†’ limpieza de `offset`, `name`, `unit`, min/max...
* `_process_access_permissions()` â†’ calcula permisos R/W.
* `_determine_data_length()` â†’ asigna 1bit / 16bit / s16.
* `_apply_deep_classification()` â†’ corrige categorÃ­as internas.
* `_apply_sampling_rules()` â†’ frecuencia recomendada segÃºn tipo.
* `_apply_view_rules()` â†’ vista recomendada (basic/simple).
* `_apply_localization()` â†’ genera JSON l10n multilenguaje.
* `_apply_system_configuratiom()` â†’ duplicados, reglas SYSTEM.
* `_apply_range_rules()` â†’ corrige valores fuera de [-32767, 32767].
* `_add_default_columns()` â†’ columns faltantes.

## 3.3 CaracterÃ­sticas especiales del Excel

* Manejo del **color verde** para identificar grupos/categorÃ­as.
* ReparaciÃ³n avanzada de rango (`value` clip).
* Compatibilidad con celdas vacÃ­as y headers dinÃ¡micos.

---

# 4. Arquitectura de **Keyter.py** (Procesador HTML)

## 4.1 Flujo principal

```
process_html() â†’ recibe bytes de HTML
â”‚
â””â”€> pd.read_html() para extraer tablas
â”‚
â”œâ”€ Filtrar tabla 0 (suele ser tÃ­tulo/cabecera)
â””â”€ Procesar tablas 1..N con _process_dataframe()
```

## 4.2 Diferencias con el procesador Excel

* No existe sistema de colores (no hay "is_green").
* Detecta columnas "Read/Write" o "Direction".
* Normaliza categorÃ­as: ANALOG, INTEGER, DIGITAL.
* AnÃ¡lisis de alarmas por patrones en `name`.
* Inserta `l10n` en inglÃ©s por defecto.

## 4.3 Funciones principales

* `_apply_column_mapping1()` â†’ mapea columnas HTML propias.
* `_process_access_permissions()` â†’ permisos segÃºn tipo.
* `_process_specific_columns()` â†’ normalizaciÃ³n `category`, alarmas, duplicados.
* `_apply_deep_classification()` â†’ clasificaciÃ³n avanzada SET_POINT, COMMAND, etc.
* `_determine_data_length()` â†’ 16bit/s16 segÃºn min/max.
* `_apply_sampling_rules()`.
* `_apply_view_rules()`.
* `_apply_specific_rules()`.
* `_add_default_columns()`.

---

# 5. Modelo de Datos Final

Ambos backends generan un DataFrame final con las columnas definidas en `LIBRARY_COLUMNS`, asegurando:

* Identificador Ãºnico (`id`).
* Campos R/W normalizados.
* CategorÃ­a final (`system_category`).
* LocalizaciÃ³n JSON (`l10n`).
* `tags`, `metadata`, `alarm`, etc.
* Columnas opcionales (`mqtt`, `json`, `notes`, etc.).

---

# 6. Principios de DiseÃ±o

* **Idempotencia**: procesar dos veces produce el mismo resultado.
* **Tolerancia a errores**: si una hoja fallaba, continÃºa con el resto.
* **Escalabilidad**: permite aÃ±adir nuevos mapeos por reglas.
* **Multi-input**: acepta Excel multipestaÃ±a o HTML multitabla.
* **Salida unificada**: siempre mismo formato final.

---

# 7. Posibles Extensiones Futuras

* IntegraciÃ³n con API REST.
* ValidaciÃ³n de esquemas mediante Pydantic.
* GeneraciÃ³n automÃ¡tica de documentaciÃ³n de columnas.
* Modo debug visual mostrando transformaciones paso a paso.

-------------------------------------------------------------------------------------

## Backend iPro

# Arquitectura del Backend iPro

Este documento describe la arquitectura interna del mÃ³dulo **iPro.py**, encargado de procesar archivos Excel que contienen variables de sistema provenientes de controladores iPro, y convertirlos en un DataFrame estandarizado compatible con la UI general.

---

# 1. Objetivo del Backend iPro

El backend **iPro** procesa archivos Excel que contienen variables del sistema, normalmente con estructuras heterogÃ©neas. Su propÃ³sito es:

* Leer todas las hojas del Excel.
* Normalizar columnas y formatos.
* Expandir dimensiones (arrays) en variables individuales.
* Categorizar cada variable en una de las categorÃ­as del sistema.
* Aplicar reglas de permisos, tags, mÃ¡scaras y longitudes.
* Unificar el DataFrame en el formato estÃ¡ndar Keyter.
* Devolver el resultado a la UI sin escribir archivos.

---

# 2. Flujo General del Backend

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bytes de archivo Excel â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lectura con pd.Excel   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  hojas
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Procesamiento por hoja                 â”‚
â”‚ - Limpieza columnas                    â”‚
â”‚ - Renombrado                           â”‚
â”‚ - ConversiÃ³n de registros              â”‚
â”‚ - ExpansiÃ³n de dimension ([1..N])      â”‚
â”‚ - CategorizaciÃ³n system_category       â”‚
â”‚ - Permisos R/W                         â”‚
â”‚ - Tags, mÃ¡scaras, sampling             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ concat
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataFrame unificado (raw)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ filtro y orden
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ finalize_dataframe()           â”‚
â”‚ - columnas por defecto         â”‚
â”‚ - reindexado LIBRARY_COLUMNS   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataFrame final iPro   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 3. Componentes Principales

## 3.1 Carga y lectura del Excel

El backend opera siempre desde **bytes** para integrarse con la UI.

Cada hoja se procesa por separado:

* Se elimina la primera fila (cabecera doble habitual).
* Se normalizan nombres de columnas.
* Se eliminan columnas `Unnamed`.
* Se renombran usando `COLUMN_MAPPING`.

---

# 4. MÃ³dulos de Procesamiento Interno

Este backend trabaja por etapas, aplicando funciones puras sobre el DataFrame.

## 4.1 ExpansiÃ³n de dimensiones (`expand_dimension_to_rows_name_bits`)

Convierte filas del tipo:

```
NOMBRE: SONDAS
DIMENSION: [1..4]
```

en 4 filas hijas:

```
SONDAS_1
SONDAS_2
SONDAS_3
SONDAS_4
```

Con reglas:

* Cada hija tiene length=1bit.
* El padre conserva una fila que indica el total de bits.
* Se ajustan registros correlativos.

---

## 4.2 CategorizaciÃ³n del sistema (`categorize_system`)

Define `system_category` mediante reglas:

### Por columnas:

* PARAMETROS_CONFIGURACION â†’ CONFIG_PARAMETER
* ALARMAS, WARNINGS â†’ ALARM
* COMANDOS â†’ COMMAND
* ESTADOS â†’ STATUS
* INSTANCIAS/REGISTRO â†’ DEFAULT
* SISTEMA â†’ SYSTEM

### Por nombre:

* PB_, SONDAS_ â†’ ANALOG_INPUT
* AO_, SALIDA_ANALOG_ â†’ ANALOG_OUTPUT
* DI_ â†’ DIGITAL_INPUT
* RELE_, RL_ â†’ DIGITAL_OUTPUT
* VERSION_ â†’ SYSTEM

### Resultado:

Solo se conservan las categorÃ­as vÃ¡lidas.

---

## 4.3 Permisos R/W (`apply_rw_permissions`)

Basado en:

* Columna `attribute`: READ, READWRITE, WRITE.
* Tipo de sistema (ALARM, STATUS, COMMANDâ€¦)

Resultado:

* R = 3, W = 0
* RW = 3/16 o 0/16 segÃºn categorÃ­a

---

## 4.4 Reglas de min/max (`apply_min_max`)

AsignaciÃ³n simple:

* COMMAND, CONFIG_PARAMETER, ALARM â†’ min=0, max=1
* Otros tipos â†’ 0/0

---

## 4.5 NormalizaciÃ³n de longitudes (`normalize_length`)

Convierte cualquier valor a:

* 1bit, 2bit, 4bit, 8bit, 16bit

---

## 4.6 EliminaciÃ³n y correcciÃ³n de nombres duplicados (`fix_duplicate_names`)

Sufijos automÃ¡ticos: `NAME`, `NAME_2`, `NAME_3`, etc.

---

## 4.7 LÃ³gica de mÃ¡scaras (`_apply_mask_logic`)

Reglas especiales:

* Para cada padre sin sufijo, asignar mÃ¡scaras 0x1, 0x2, 0x4... a hijas.
* Si existen mÃ¡s de 16, reiniciar secuencia.

---

## 4.8 Tags (`assign_tags`)

Asigna:

* SISTEMA â†’ ["library_identifier"]
* Otros â†’ []

---

## 4.9 Sampling (`_apply_sampling_rules`)

Frecuencias segÃºn categorÃ­a:

* ALARM â†’ 30
* STATUS â†’ 60
* ANALOG_INPUT â†’ 60
* COMMAND / CONFIG_PARAMETER â†’ 0

---

## 4.10 FinalizaciÃ³n (`finalize_dataframe`)

Aplica valores por defecto y crea el DataFrame final:

* Relleno de metadatos.
* Campo l10n mÃ­nimo.
* Orden de columnas por LIBRARY_COLUMNS.

---

# 5. FunciÃ³n Principal `convert_excel_to_dataframe`

Es el punto de entrada para la UI.

Responsabilidades:

1. Leer todas las hojas.
2. Procesar cada una.
3. Unificarlas.
4. Filtrar registros vÃ¡lidos.
5. Ordenar, asignar IDs, fijar view="simple".
6. Ejecutar `finalize_dataframe`.

Devuelve un DataFrame completamente homogÃ©neo.

---

# 6. Arquitectura Resumida en MÃ³dulos

```
iPro Backend
â”‚
â”œâ”€â”€ Lectura de Excel
â”‚
â”œâ”€â”€ Limpieza y normalizaciÃ³n
â”‚
â”œâ”€â”€ ExpansiÃ³n de dimensiones
â”‚
â”œâ”€â”€ Categorization engine
â”‚   â”œâ”€â”€ by groups
â”‚   â”œâ”€â”€ by name
â”‚   â”œâ”€â”€ tag logic
â”‚   â””â”€â”€ system filtering
â”‚
â”œâ”€â”€ Permissions engine
â”‚
â”œâ”€â”€ Mask engine
â”‚
â”œâ”€â”€ Sampling engine
â”‚
â”œâ”€â”€ Normalize bit-length
â”‚
â””â”€â”€ Finalization
    â”œâ”€â”€ default columns
    â”œâ”€â”€ id + view
    â””â”€â”€ reindex
```

---

# 7. Principios de DiseÃ±o

* **Pure functions**: cada paso es una transformaciÃ³n aislada.
* **Extensibilidad**: permite agregar nuevas reglas fÃ¡cilmente.
* **Robustez**: ignora hojas invÃ¡lidas.
* **Homogeneidad**: siempre regresa formato LIBRARY_COLUMNS.
* **Soporte multilenguaje mÃ­nimo** mediante l10n por defecto.

---

# 8. Mejoras Futuras

* Auto-detecciÃ³n avanzada de categorÃ­as.
* ValidaciÃ³n estructural con Pydantic.
* Mapeos por configuraciÃ³n externa (YAML).
* MÃ³dulo de exportaciÃ³n opcional.
* Vista previa visual de jerarquÃ­a padre â†’ hijas.

-----------------------------------------------------------------------------------------

## Backend cefa.py

# Arquitectura del Backend CEFA (procesamiento PDF)

Este documento describe la arquitectura interna del mÃ³dulo **cefa.py**, encargado de procesar archivos PDF que contienen tablas con informaciÃ³n de registros Modbus o similares, y convertirlos en un DataFrame estandarizado compatible con el modelo de datos general Keyter.

---

# 1. Objetivo del Backend CEFA

El backend **CEFA** se especializa en:

* Extraer tablas desde PDFs escaneados o generados digitalmente.
* Limpiar encabezados y normalizar columnas.
* Interpretar bloques de escritura/lectura.
* Propagar categorÃ­as basadas en duplicados y filas vacÃ­as.
* Clasificar cada variable en system_category.
* Aplicar reglas de unidades, rangos, mÃ¡scaras y permisos.
* Devolver un DataFrame estandarizado segÃºn `LIBRARY_COLUMNS`.

Su enfoque es transformar documentos PDF no estructurados en una biblioteca digital normalizada.

---

# 2. Flujo General del Backend

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bytes PDF                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ pdfplumber.extract_tables  â”‚ â†’ mÃºltiples DataFrames crudos
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼ concat
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NormalizaciÃ³n inicial      â”‚
â”‚ - Limpieza de encabezados  â”‚
â”‚ - Renombrado de columnas   â”‚
â”‚ - ConversiÃ³n de nÃºmeros    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Motor de Procesamiento CEFA          â”‚
â”‚ - apply_read_write_flags             â”‚
â”‚ - propagate_context                  â”‚
â”‚ - propagate_empty_register_category  â”‚
â”‚ - adjust_system_category             â”‚
â”‚ - _apply_view_rules                  â”‚
â”‚ - _apply_sampling_rules              â”‚
â”‚ - _process_access_permissions        â”‚
â”‚ - _apply_range_rules                 â”‚
â”‚ - _apply_unit_rules                  â”‚
â”‚ - _apply_mask_logic                  â”‚
â”‚ - _apply_length_rules                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agregar columnas faltantes â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataFrame final (LIBRARY_COLUMNS)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 3. Componentes Principales

## 3.1 Lectura del PDF

* Usa **pdfplumber** para extraer todas las tablas de cada pÃ¡gina.
* Cada tabla se convierte en un DataFrame.
* Se concatenan todas en un Ãºnico DataFrame crudo.

## 3.2 Limpieza de encabezados

* La primera fila del PDF suele contener los encabezados.
* Se eliminan duplicados aÃ±adiendo sufijos (`col`, `col_1`, `col_2`, ...).
* Se renombran columnas segÃºn `COLUMN_MAPPING_PDF`:

  * `DIRECCION` â†’ register
  * `Nombre` â†’ name
  * `Longitud Word Dato` â†’ length
  * `Valores` â†’ description

## 3.3 NormalizaciÃ³n inicial

* Se convierten minvalue, maxvalue, offset a numÃ©ricos.
* Se limpian strings en register, name, description.

---

# 4. MÃ³dulos de Procesamiento Interno

## 4.1 apply_read_write_flags(df)

Interpreta bloques del PDF:

* "LECTURA" activa modo lectura.
* "ESCRITURA" activa modo escritura.
* Los registros posteriores heredan `R` o `W`.
* Las filas de encabezado se eliminan.

## 4.2 propagate_context(df)

Usa duplicados de `register` para crear categorÃ­as:

* La primera apariciÃ³n define un nombre de categorÃ­a.
* Las repeticiones heredan la categorÃ­a.
* Se eliminan encabezados excepto si empiezan por `AL`.

## 4.3 propagate_empty_register_category(df)

Permite interpretar **bloques vacÃ­os** como encabezados.

* Cuando register estÃ¡ vacÃ­o â†’ el name define una categorÃ­a.
* Las filas siguientes heredan esa categorÃ­a.
* Luego se elimina la fila vacÃ­a.

## 4.4 adjust_system_category(df)

Clasificador central basado en reglas:

* category empieza por AL â†’ ALARM
* name empieza por CONTROL, RESET â†’ COMMAND
* name empieza por SP, CONSIGNA â†’ SET_POINT
* P_, NIVEL, TPO, OFFSET â†’ CONFIG_PARAMETER
* ANALOGICAS, CONTROL_EQUIPOS, ESTADO_EQUIPOS â†’ mapeo directo a tipos del sistema

## 4.5 _apply_view_rules()

Define la vista recomendada:

* ALARM â†’ simple
* STATUS â†’ basic
* SET_POINT â†’ simple
* COMMAND â†’ simple

## 4.6 _apply_length_rules()

Longitudes por system_category:

* ALARM â†’ 1bit
* COMMAND â†’ 1bit
* STATUS â†’ f32cdab
* SET_POINT â†’ f32cdab
* DEFAULT â†’ s16

## 4.7 _apply_sampling_rules()

Asigna tiempos de muestreo:

* ALARM â†’ 30
* STATUS â†’ 60
* SET_POINT â†’ 300
* COMMAND â†’ 0

TambiÃ©n asigna **tags** cuando system_category = SYSTEM.

## 4.8 _process_access_permissions()

Convierte access_type y system_category en permisos numÃ©ricos:

* ALARM â†’ read=1 / write=0
* STATUS â†’ read=4 / write=0
* COMMAND â†’ read=0 / write=6
* SET_POINT â†’ read=3 / write=6

## 4.9 _apply_range_rules()

Rangos segÃºn tipo:

* ALARM, COMMAND â†’ [0,1]
* ANALOG_OUTPUT TEMP â†’ [-270,270]
* ANALOG_OUTPUT otros â†’ [0,9999]
* CONFIG_PARAMETER â†’ reglas P_, NIVEL, AJUSTE...
* SET_POINT â†’ [0,9999]

## 4.10 _apply_unit_rules()

Unidades automÃ¡ticas:

* TEMP â†’ ÂºC
* PRESION â†’ bar
* CAUDALIMETRO â†’ m3/s

## 4.11 _apply_mask_logic()

Asigna mÃ¡scaras para registros tipo BIT:

* 0x1, 0x2, 0x4, ..., 0x8000
* Reinicio cada 16 bits

---

# 5. FunciÃ³n Principal: process_pdf(pdf_content)

Responsabilidades:

1. Leer PDF y extraer tablas.
2. Normalizar encabezados.
3. Renombrar columnas y limpiar tipos.
4. Ejecutar el pipeline completo de reglas.
5. Asegurar columnas por defecto.
6. Reindexar segÃºn LIBRARY_COLUMNS.
7. Asignar ID secuencial.

Devuelve un DataFrame completamente estandarizado.

---

# 6. Arquitectura Resumida

```
CEFA Backend
â”‚
â”œâ”€â”€ ExtracciÃ³n PDF
â”‚
â”œâ”€â”€ NormalizaciÃ³n inicial
â”‚
â”œâ”€â”€ Motor de categorÃ­as
â”‚   â”œâ”€â”€ propagate_context
â”‚   â””â”€â”€ propagate_empty_register_category
â”‚
â”œâ”€â”€ ClasificaciÃ³n
â”‚   â””â”€â”€ adjust_system_category
â”‚
â”œâ”€â”€ Reglas adicionales
â”‚   â”œâ”€â”€ read/write
â”‚   â”œâ”€â”€ ranges
â”‚   â”œâ”€â”€ units
â”‚   â”œâ”€â”€ sampling
â”‚   â”œâ”€â”€ masks
â”‚   â””â”€â”€ length
â”‚
â””â”€â”€ FinalizaciÃ³n
    â””â”€â”€ LIBRARY_COLUMNS
```

---

# 7. Principios de DiseÃ±o

* **Robustez ante PDFs desestructurados**.
* **HeurÃ­sticas fuertes** para interpretar encabezados.
* **Pipeline secuencial** claro y extendible.
* **NormalizaciÃ³n consistente** con otros backends.
* **Total alineaciÃ³n con LIBRARY_COLUMNS**.

---

# 8. Mejoras Futuras

* OCR opcional para PDFs sin tablas.
* Reconocimiento automÃ¡tico de estructuras mediante ML.
* ConfiguraciÃ³n YAML para reglas externas.
* VisualizaciÃ³n del Ã¡rbol de categorÃ­as.

--------------------------------------------------------------------------------------------

## Backend dixell2.py

## Arquitectura: Backend dixell2.py

# 1. VisiÃ³n General

El backend dixell2.py procesa manuales Dixell en PDF que son complejos y multiformato, y extrae tablas de parÃ¡metros estructuradas para producir un DataFrame unificado que coincide con el esquema de la biblioteca de la aplicaciÃ³n. Realiza un anÃ¡lisis robusto de PDF, clasificaciÃ³n de secciones, inferencia de encabezados, normalizaciÃ³n de valores y generaciÃ³n de metadatos de campos Modbus.

Este backend estÃ¡ diseÃ±ado para:

* **Parsear mÃºltiples formatos de tablas PDF heterogÃ©neas.**
* **Detectar lÃ­mites de secciones mediante reglas de equivalencia de encabezados.**
* **Normalizar estructuras de tabla mÃºltiples (dos familias principales: COLUMNAS_VALIDAS1 y COLUMNAS_VALIDAS2).**
* **Extraer registro, nombre, tipo, rango, unidades, permisos, categorÃ­as.**
* **Limpiar texto, eliminar duplicados de nombres de variables y sanear caracteres especiales.**
* **Mapear los datos extraÃ­dos al esquema unificado LIBRARY_COLUMNS.**

Es uno de los backends mÃ¡s complejos debido a la estructura extremadamente inconsistente de los documentos Dixell.

---

# 2. Flujo de Datos

# Pipeline de Alto Nivel

Bytes PDF
   â†“
process_dixell()
   â†“  (PyMuPDF)
Detectar zonas de dibujo/color (metadatos opcionales)
   â†“  (pdfplumber)
Extraer tablas crudas pÃ¡gina por pÃ¡gina
   â†“
Clasificador de secciones usando ENCABEZADOS_EQUIVALENTES
   â†“
Agrupar tablas por secciÃ³n detectada
   â†“
Para cada secciÃ³n:
    - Limpiar filas vacÃ­as
    - Detectar fila de encabezado
    - Eliminar filas meta (HEX, DEC, etc.)
    - Normalizar nombres de columnas
    - Seleccionar esquema de columnas apropiado (1 o 2)
   â†“
Unir todas las tablas estructuradas
   â†“
Aplicar mapeo de columnas
   â†“
DecodificaciÃ³n de registros (hex â†’ dec)
   â†“
Inferencia de categorÃ­a
   â†“
Inferencia de permisos de acceso (R/W)
   â†“
Reglas de muestreo
   â†“
Reglas de vista
   â†“
DerivaciÃ³n de longitud/tipo de dato
   â†“
Inferencia de unidades
   â†“
Inferencia de rangos (min/max)
   â†“
Limpieza de texto + eliminaciÃ³n de caracteres invÃ¡lidos
   â†“
Reindexado al esquema final â†’ LIBRARY_COLUMNS

--

# 3. Componentes Principales

## 3.1 ExtracciÃ³n de Tablas del PDF

* **Usa PyMuPDF (fitz) para detectar zonas coloreadas â€” usadas como metadatos opcionales.**
* **Usa pdfplumber como extractor principal porque tolera mejor filas irregulares.**
* **Cada pÃ¡gina puede contener:**
   *Secciones nombradas (usando ENCABEZADOS_EQUIVALENTES)*
   *Subtablas crudas aÃ±adidas a la Ãºltima secciÃ³n detectada*
   *Secciones que caen en SinClasificar si no se detecta encabezado*

## 3.2 NormalizaciÃ³n de Secciones

Las secciones se identifican escaneando el texto de la primera fila de cada tabla y haciendo match con **ENCABEZADOS_EQUIVALENTES**. Ejemplos:

```
"ANALOG INPUT" â†’ ANALOG INPUT
"SET POINT", "SP" â†’ SET POINT
"DEVICE STATUS" â†’ Device Status
"ALARM", "ALARMS" â†’ ALARMS
```

Estos nombres canÃ³nicos se convierten en la system_category inicial de la variable.

---

# 4. DetecciÃ³n y Mapeo de Encabezados

Las tablas Dixell siguen dos formatos principales:

```
Familia 1 (COLUMNAS_VALIDAS1) â†’ tablas tÃ­picas de ingenierÃ­a
Familia 2 (COLUMNAS_VALIDAS2) â†’ tablas compactas en formato hexadecimal
```

El backend decide dinÃ¡micamente quÃ© mapeo usar por tabla mediante:

* **Escaneo de la primera fila utilizable**
* **Conteo de coincidencias de nombre de columna con cada familia**
* **SelecciÃ³n de la familia con el puntaje mÃ¡s alto**

Luego las columnas se normalizan usando:

* **COLUMN_MAPPING1**
* **COLUMN_MAPPING2**

Estos mapean campos legibles como "Read Register", "Format", "VAR NAME" a campos internos como register, length, name, etc.

# 5. LÃ³gica de ExtracciÃ³n de Valores

## 5.1 Parseo de Registro

Los registros pueden venir de cualquiera de estas columnas:

* **Read Register**
* **Write Register**
* **Register**
* **REGISTER[hex]**

Los registros se normalizan usando hex_to_dec().

# 5.2 ExtracciÃ³n de min/max

Los rangos se extraen de la columna â€œTypeâ€ usando patrones regex:

* **"0Â°C to 50Â°C"**

* **"-10 to 200"**

* **"0 bar to 16 bar"**

```
Resultado â†’ minvalue, maxvalue, unit.
``` 

# 5.3 Unidades

La normalizaciÃ³n de unidades incluye:

* **Â°C, C â†’ "Â°C"**
* **sec, seg â†’ "s"**
* **m â†’ "min"**

--------------------------------------------------------------------------

# 6. Inferencia de CategorÃ­a del Sistema

Las reglas estÃ¡n en _process_specific_columns():

* **Basado en nombre de secciÃ³n â†’ categorÃ­a primaria**
* **Basado en coincidencias del nombre (contiene "input" â†’ DIGITAL_INPUT; "output" â†’ DIGITAL_OUTPUT)**
* **Etiquetas agregadas automÃ¡ticamente para SYSTEM**

---------------------------------------------------------------------------

# 7. Inferencia de Permisos (R/W)

Los permisos se derivan de:

* **Columna R / W o R/W**

* **Sobrescrituras dependientes de categorÃ­a:**
     *ALARM â†’ read=1*
     *STATUS â†’ read=1*
     *SET_POINT â†’ read=3, write=16*
     *COMMAND â†’ solo escritura*
     *DIGITAL_OUTPUT â†’ read=1 / write=0*